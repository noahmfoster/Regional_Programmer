{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_gbhzuJwsPT-"
      },
      "source": [
        "# The Full Project\n",
        "\n",
        "The full requirements for this project are stored in the env.yml file. \n",
        "Also very possible that you do not have the models downloaded. The language model can be retrieved by running the get_LM_checkpoints.py script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eJ9H3BOGuce4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-09 04:11:14.603831: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# This line sneakily imports a lot of modules. Could well be slow.\n",
        "from model import AtRM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HD-4UTfqsKw-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Vision models...\n",
            "CLIP model loaded\n",
            "Something is missing!\n",
            "Vision models loaded.\n",
            "Loading Language models...\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /Users/noah/Library/CloudStorage/GoogleDrive-noah_foster@brown.edu/.shortcut-targets-by-id/1SYMhu5p-9RN6dviOibb7YlXUWV67Z4e3/Final Project/git_version/Regional_Programmer/LanguageModel/Model/.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m AtRM(verbose \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, lm \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mtuned\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(model)\n",
            "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-noah_foster@brown.edu/.shortcut-targets-by-id/1SYMhu5p-9RN6dviOibb7YlXUWV67Z4e3/Final Project/git_version/Regional_Programmer/model.py:44\u001b[0m, in \u001b[0;36mAtRM.__init__\u001b[0;34m(self, verbose, lm)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mVision models loaded.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoading Language models...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m get_language_model(model_name \u001b[39m=\u001b[39;49m lm)\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m verbose: \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLanguage models loaded.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m is_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n",
            "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-noah_foster@brown.edu/.shortcut-targets-by-id/1SYMhu5p-9RN6dviOibb7YlXUWV67Z4e3/Final Project/git_version/Regional_Programmer/LanguageModel/Language.py:29\u001b[0m, in \u001b[0;36mget_language_model\u001b[0;34m(model_name, model_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_language_model\u001b[39m(model_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrained\u001b[39m\u001b[39m'\u001b[39m, model_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m model_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtuned\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 29\u001b[0m         \u001b[39mreturn\u001b[39;00m get_tuned(model_path\u001b[39m=\u001b[39;49mmodel_path)\n\u001b[1;32m     30\u001b[0m     \u001b[39melif\u001b[39;00m model_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39muntuned\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     31\u001b[0m         \u001b[39mreturn\u001b[39;00m get_untuned()\n",
            "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-noah_foster@brown.edu/.shortcut-targets-by-id/1SYMhu5p-9RN6dviOibb7YlXUWV67Z4e3/Final Project/git_version/Regional_Programmer/LanguageModel/Language.py:13\u001b[0m, in \u001b[0;36mget_tuned\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m model_path \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     12\u001b[0m     model_path \u001b[39m=\u001b[39m model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(\u001b[39m__file__\u001b[39m)) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Model/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 13\u001b[0m fine_tuned_model \u001b[39m=\u001b[39m GPT2LMHeadModel\u001b[39m.\u001b[39;49mfrom_pretrained(model_path)\n\u001b[1;32m     14\u001b[0m tokenizer \u001b[39m=\u001b[39m GPT2TokenizerFast\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mgpt2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m fine_tuned_model, tokenizer\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/modeling_utils.py:2045\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2039\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2040\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError no file named \u001b[39m\u001b[39m{\u001b[39;00mWEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m found in directory \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2041\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthere is a file for Flax weights. Use `from_flax=True` to load this model from those \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2042\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mweights.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2043\u001b[0m         )\n\u001b[1;32m   2044\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2045\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2046\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError no file named \u001b[39m\u001b[39m{\u001b[39;00mWEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mTF_WEIGHTS_NAME \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2047\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m found in directory \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2048\u001b[0m         )\n\u001b[1;32m   2049\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(subfolder, pretrained_model_name_or_path)):\n\u001b[1;32m   2050\u001b[0m     archive_file \u001b[39m=\u001b[39m pretrained_model_name_or_path\n",
            "\u001b[0;31mOSError\u001b[0m: Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /Users/noah/Library/CloudStorage/GoogleDrive-noah_foster@brown.edu/.shortcut-targets-by-id/1SYMhu5p-9RN6dviOibb7YlXUWV67Z4e3/Final Project/git_version/Regional_Programmer/LanguageModel/Model/."
          ]
        }
      ],
      "source": [
        "model = AtRM(verbose = True, lm = \"tuned\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fb_QWF8uVBr"
      },
      "source": [
        "## Importing the models!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2unrnlTuUn8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb79b4760a3db271a0094282eed73d55c4f5e3b07e2a097a4c69ffa68186c117"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
