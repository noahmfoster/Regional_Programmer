{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training GPT-J to replicate the Office Script\n",
        "\n",
        "\n",
        "### Importing the Script\n",
        "* From Kagle: https://www.kaggle.com/datasets/nasirkhalid24/the-office-us-complete-dialoguetranscript\n",
        "\n",
        "### Standardizing the way that information is presented to the Model\n",
        "* We need some standard format that will match the outputs of the vision team. We should probabily make a class for this with methods that can send the prompt to the model\n",
        "### Importing the Model\n",
        "* From HuggingFace (the transformers library), we will import GPT-J\n",
        "* https://huggingface.co/EleutherAI/gpt-j-6B\n",
        "### Tuning\n",
        "\n",
        "## Attempt 2: Custom Transformer (probably will suck)\n",
        "\n",
        "### Buidling the Model\n",
        "### Pre-training\n",
        "### Fine tuning"
      ],
      "metadata": {
        "id": "-tk7O2ZLbf0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### General Imports"
      ],
      "metadata": {
        "id": "40rby5vffTTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8mAsHH_fWDK",
        "outputId": "30b60410-09b5-47f4-d9b1-9bc0f9ac614a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcNxEQY4qY8Q",
        "outputId": "5d389a04-7a2e-4564-a22c-81be6dd8c883"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Brown\t\t   'Copy of gnn_lab.ipynb'   released_lab_gnn\n",
            " CERTIFICATES\t   'Final Project'\t     The-Office-Lines-V4.csv\n",
            "'Colab Notebooks'   released_lab\t    'VEDANT SOP.docx'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = \"drive/Shareddrives/Final Project Data/The-Office-Lines-V4.csv\"\n",
        "data = pd.read_csv(data_file)\n",
        "data = data.drop(\"Unnamed: 6\", axis=1)\n",
        "\n",
        "print(data[:5]) # Probably need to delete the last line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rw_5ZKChzCT",
        "outputId": "9dcd7bce-30ca-44aa-8cdd-34831322e230"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   season  episode  title  scene  speaker  \\\n",
            "0       1        1  Pilot      1  Michael   \n",
            "1       1        1  Pilot      1      Jim   \n",
            "2       1        1  Pilot      1  Michael   \n",
            "3       1        1  Pilot      1      Jim   \n",
            "4       1        1  Pilot      1  Michael   \n",
            "\n",
            "                                                line  \n",
            "0  All right Jim. Your quarterlies look very good...  \n",
            "1         Oh, I told you. I couldn't close it. So...  \n",
            "2  So you've come to the master for guidance? Is ...  \n",
            "3         Actually, you called me in here, but yeah.  \n",
            "4    All right. Well, let me show you how it's done.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the Data\n",
        "\n",
        "* Collect it by scene"
      ],
      "metadata": {
        "id": "d5Hn3mPwfGIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Keys of the dictionary will be scenes, Values will be a list of lines by each chracter\n",
        "data_dictionary = {}\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "  if row['scene'] not in data_dictionary:\n",
        "    data_dictionary[row['scene']] = []\n",
        "\n",
        "  data_dictionary[row['scene']].append(  ( row['speaker'], row['line'] ) )\n",
        "\n"
      ],
      "metadata": {
        "id": "6ECI5b8trgVv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dictionary[1]"
      ],
      "metadata": {
        "id": "QhVDGTj7fFqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f74ed1-083c-42be-e821-79fdebfcc75d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Michael',\n",
              "  'All right Jim. Your quarterlies look very good. How are things at the library?'),\n",
              " ('Jim', \"Oh, I told you. I couldn't close it. So...\"),\n",
              " ('Michael',\n",
              "  \"So you've come to the master for guidance? Is this what you're saying, grasshopper?\"),\n",
              " ('Jim', 'Actually, you called me in here, but yeah.'),\n",
              " ('Michael', \"All right. Well, let me show you how it's done.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standardizing Presentation of the TexT\n",
        "\n",
        "Example of what we want to prompt the model with:\n",
        "\n",
        "Prompt:\n",
        "\n",
        "> Characters: Jim, Pam \\\\\n",
        "> Objects in Scene: <What do we put here?> \\\\\n",
        "> Lines:\n",
        ">> Jim: Good morning, Pam \\\\\n",
        ">> Pam:\n",
        "\n",
        "Expected Text Completion:\n",
        "> Characters: Jim, Pam \\\\\n",
        "> Objects in Scene: <What do we put here?> \\\\\n",
        "> Lines:\n",
        ">> Jim: Good morning, Pam \\\\\n",
        ">> Pam: **Good morning, Jim!**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rq9-I7cAgsDx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "VzO_YrEkutgJ",
        "outputId": "3b90c089-ee18-45ad-9392-69dddb34e52a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Characters: /n a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class scene():\n",
        "#     def __init__(self, characters = []) -> None:\n",
        "#         self.characters = characters\n",
        "\n",
        "#     def to_text(self):\n",
        "#         output = f\"Characters: \"\n",
        "\n",
        "\n",
        "class PromptGenerator:\n",
        "  def __init__(self, data):\n",
        "    assert type(data) == dict\n",
        "    self.data       = data ### Dictionary where keys of the dictionary will be scenes, Values will be a list of lines by each chracter\n",
        "    self.scenes     = set(self.data.keys())\n",
        "    self.num_scenes = len(self.scenes)\n",
        "\n",
        "  def to_text(self):\n",
        "    text = \"\"\n",
        "    for scene in self.scenes:\n",
        "      text += self.get_prompt_for_scene(scene)  + \" \\n \" # TODO: append new line to sentence\n",
        "\n",
        "    return text \n",
        "\n",
        "  def get_prompt_for_scene(self, scene_number):\n",
        "    assert scene_number in self.data\n",
        "\n",
        "    scene_data                              = self.data[scene_number]\n",
        "    _, characters_string, lines_in_scene    = self.get_characters_in_scene_and_lines(scene_number)\n",
        "    objects_in_scene                        = self.get_all_nouns_in_scene(lines_in_scene)\n",
        "\n",
        "\n",
        "    prompt       = \"Characters: \" + characters_string  + \" \\n \"   # TODO: append new line to sentence\n",
        "    prompt      += \"Objects in Scene: \" + objects_in_scene  + \" \\n \" # TODO: Figure out how to generate what objects to put in scene  # TODO: append new line to sentence\n",
        "    prompt      += \"Lines: \" + \" \\n \".join( lines_in_scene ) \n",
        "\n",
        "    return prompt\n",
        "\n",
        "\n",
        "  def get_characters_in_scene_and_lines(self, scene_number):\n",
        "    scene_data  = self.data[scene_number]\n",
        "\n",
        "    characters_list = []\n",
        "    lines_in_scene      = []\n",
        "    for line_and_character in scene_data:\n",
        "      characters_list.append(line_and_character[0])\n",
        "      lines_in_scene.append(line_and_character[0] + \": \" + line_and_character[1]) # TODO: append new line to sentence\n",
        "\n",
        "    characters_string = \", \".join(characters_list)\n",
        "\n",
        "    return characters_list, characters_string, lines_in_scene\n",
        "\n",
        "  def get_all_nouns_in_scene(self, text):\n",
        "    if type(text) == list:\n",
        "      text = \" \".join(text)\n",
        "    ## TODO: Think about this more and work on later \n",
        "    ## TODO: Remove names\n",
        "    temp = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(text)) if pos[0] == 'N' and (pos != 'NNP')]\n",
        "    return \" \".join( temp )\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "OcRU82Fsgwqp"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "promptGenerator = PromptGenerator(data_dictionary)"
      ],
      "metadata": {
        "id": "-6jbHrN0ys37"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "promptGenerator.get_prompt_for_scene(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "PoXAwijWywbX",
        "outputId": "a09e5c82-8c04-4cd5-b13d-091f632ff0af"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Characters: Michael, Jim, Michael, Jim, Michael \\n Objects in Scene: quarterlies things library master guidance grasshopper right \\n Lines: Michael: All right Jim. Your quarterlies look very good. How are things at the library? \\n Jim: Oh, I told you. I couldn't close it. So... \\n Michael: So you've come to the master for guidance? Is this what you're saying, grasshopper? \\n Jim: Actually, you called me in here, but yeah. \\n Michael: All right. Well, let me show you how it's done.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#https://stackoverflow.com/questions/33587667/extracting-all-nouns-from-a-text-file-using-nltk\n",
        "\n",
        "\n",
        "txt = \"\"\"Natural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages.\"\"\"\n",
        "print([word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(txt)) if pos[0] == 'N'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9AbMJ4swSy9",
        "outputId": "53c3a0b7-79e0-4430-b87e-157eb281c217"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['language', 'processing', 'NLP', 'field', 'computer', 'science', 'intelligence', 'linguistics', 'interactions', 'computers', 'languages']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the Model"
      ],
      "metadata": {
        "id": "Ae9v2SAYfAn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ADnIpv_bboH"
      },
      "outputs": [],
      "source": [
        "https://www.kaggle.com/datasets/nasirkhalid24/the-office-us-complete-dialoguetranscript"
      ]
    }
  ]
}